{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Deligram\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Deligram\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#libraries used to extract, clean and manipulate the data\n",
    "from helpers import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "#To plot the graphs\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "#library used to count the frequency of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#To create the sentiment analysis model, tokenization and lemmatization\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk.data\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv file by pandas\n",
    "tx_data = pd.read_csv('all_lyrics_2.csv', encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>WeekID</th>\n",
       "      <th>Week Position</th>\n",
       "      <th>Song</th>\n",
       "      <th>Performer</th>\n",
       "      <th>SongID</th>\n",
       "      <th>Instance</th>\n",
       "      <th>Previous Week Position</th>\n",
       "      <th>Peak Position</th>\n",
       "      <th>Weeks on Chart</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1963-0...</td>\n",
       "      <td>6/1/1963</td>\n",
       "      <td>11</td>\n",
       "      <td>Still</td>\n",
       "      <td>Bill Anderson</td>\n",
       "      <td>StillBill Anderson</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[Chorus 1]\\n(Still)\\nThough you broke my heart...</td>\n",
       "      <td>Bill Anderson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1967-0...</td>\n",
       "      <td>1/7/1967</td>\n",
       "      <td>11</td>\n",
       "      <td>Coming Home Soldier</td>\n",
       "      <td>Bobby Vinton</td>\n",
       "      <td>Coming Home SoldierBobby Vinton</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>I'm coming home I'm coming\\nI'm coming home I'...</td>\n",
       "      <td>Bobby Vinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1971-0...</td>\n",
       "      <td>7/3/1971</td>\n",
       "      <td>11</td>\n",
       "      <td>She's Not Just Another Woman</td>\n",
       "      <td>The 8th Day</td>\n",
       "      <td>She's Not Just Another WomanThe 8th Day</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Text comes on screen reading A Netflix Origin...</td>\n",
       "      <td>Russian Doll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1975-1...</td>\n",
       "      <td>11/29/1975</td>\n",
       "      <td>11</td>\n",
       "      <td>Saturday Night</td>\n",
       "      <td>Bay City Rollers</td>\n",
       "      <td>Saturday NightBay City Rollers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>S-A-T-U-R-D-A-Y night!\\nS-A-T-U-R-D-A-Y night!...</td>\n",
       "      <td>Bay City Rollers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1987-0...</td>\n",
       "      <td>9/19/1987</td>\n",
       "      <td>11</td>\n",
       "      <td>Carrie</td>\n",
       "      <td>Europe</td>\n",
       "      <td>CarrieEurope</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[Verse 1: Joey Tempest]\\nWhen lights go down\\n...</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26435</th>\n",
       "      <td>325636</td>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1985-0...</td>\n",
       "      <td>7/27/1985</td>\n",
       "      <td>82</td>\n",
       "      <td>You Look Marvelous</td>\n",
       "      <td>Billy Crystal</td>\n",
       "      <td>You Look MarvelousBilly Crystal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Saludos, my darlings\\nAnd you know who you are...</td>\n",
       "      <td>Billy Crystal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26436</th>\n",
       "      <td>325648</td>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1963-0...</td>\n",
       "      <td>9/28/1963</td>\n",
       "      <td>70</td>\n",
       "      <td>You Lost The Sweetest Boy</td>\n",
       "      <td>Mary Wells</td>\n",
       "      <td>You Lost The Sweetest BoyMary Wells</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Intro]\\nOh yeah, oh yeah, oh yeah, oh yeah\\n\\...</td>\n",
       "      <td>Mary Wells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26437</th>\n",
       "      <td>325657</td>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1969-0...</td>\n",
       "      <td>8/2/1969</td>\n",
       "      <td>96</td>\n",
       "      <td>You Made A Believer (Out Of Me)</td>\n",
       "      <td>Ruby Andrews</td>\n",
       "      <td>You Made A Believer (Out Of Me)Ruby Andrews</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Now that I know\\nWhat it is, boy\\nGood, good l...</td>\n",
       "      <td>Ruby Andrews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26438</th>\n",
       "      <td>325659</td>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1977-0...</td>\n",
       "      <td>6/4/1977</td>\n",
       "      <td>69</td>\n",
       "      <td>You Made Me Believe In Magic</td>\n",
       "      <td>Bay City Rollers</td>\n",
       "      <td>You Made Me Believe In MagicBay City Rollers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I believed all love has gone\\nI've no strength...</td>\n",
       "      <td>Bay City Rollers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26439</th>\n",
       "      <td>325676</td>\n",
       "      <td>http://www.billboard.com/charts/hot-100/1959-0...</td>\n",
       "      <td>5/2/1959</td>\n",
       "      <td>87</td>\n",
       "      <td>You Made Me Love You</td>\n",
       "      <td>Nat King Cole</td>\n",
       "      <td>You Made Me Love YouNat King Cole</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>You made me love you\\nI didn't wanna do it\\nI ...</td>\n",
       "      <td>Nat King Cole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26440 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                                url  \\\n",
       "0               0  http://www.billboard.com/charts/hot-100/1963-0...   \n",
       "1               1  http://www.billboard.com/charts/hot-100/1967-0...   \n",
       "2               2  http://www.billboard.com/charts/hot-100/1971-0...   \n",
       "3               3  http://www.billboard.com/charts/hot-100/1975-1...   \n",
       "4               5  http://www.billboard.com/charts/hot-100/1987-0...   \n",
       "...           ...                                                ...   \n",
       "26435      325636  http://www.billboard.com/charts/hot-100/1985-0...   \n",
       "26436      325648  http://www.billboard.com/charts/hot-100/1963-0...   \n",
       "26437      325657  http://www.billboard.com/charts/hot-100/1969-0...   \n",
       "26438      325659  http://www.billboard.com/charts/hot-100/1977-0...   \n",
       "26439      325676  http://www.billboard.com/charts/hot-100/1959-0...   \n",
       "\n",
       "           WeekID  Week Position                             Song  \\\n",
       "0        6/1/1963             11                            Still   \n",
       "1        1/7/1967             11              Coming Home Soldier   \n",
       "2        7/3/1971             11     She's Not Just Another Woman   \n",
       "3      11/29/1975             11                   Saturday Night   \n",
       "4       9/19/1987             11                           Carrie   \n",
       "...           ...            ...                              ...   \n",
       "26435   7/27/1985             82               You Look Marvelous   \n",
       "26436   9/28/1963             70        You Lost The Sweetest Boy   \n",
       "26437    8/2/1969             96  You Made A Believer (Out Of Me)   \n",
       "26438    6/4/1977             69     You Made Me Believe In Magic   \n",
       "26439    5/2/1959             87             You Made Me Love You   \n",
       "\n",
       "              Performer                                        SongID  \\\n",
       "0         Bill Anderson                            StillBill Anderson   \n",
       "1          Bobby Vinton               Coming Home SoldierBobby Vinton   \n",
       "2           The 8th Day       She's Not Just Another WomanThe 8th Day   \n",
       "3      Bay City Rollers                Saturday NightBay City Rollers   \n",
       "4                Europe                                  CarrieEurope   \n",
       "...                 ...                                           ...   \n",
       "26435     Billy Crystal               You Look MarvelousBilly Crystal   \n",
       "26436        Mary Wells           You Lost The Sweetest BoyMary Wells   \n",
       "26437      Ruby Andrews   You Made A Believer (Out Of Me)Ruby Andrews   \n",
       "26438  Bay City Rollers  You Made Me Believe In MagicBay City Rollers   \n",
       "26439     Nat King Cole             You Made Me Love YouNat King Cole   \n",
       "\n",
       "       Instance  Previous Week Position  Peak Position  Weeks on Chart  \\\n",
       "0           1.0                    17.0           11.0             8.0   \n",
       "1           1.0                    17.0           11.0             8.0   \n",
       "2           1.0                    17.0           11.0             8.0   \n",
       "3           1.0                    17.0           11.0             8.0   \n",
       "4           1.0                    17.0           11.0             8.0   \n",
       "...         ...                     ...            ...             ...   \n",
       "26435       1.0                     NaN           82.0             1.0   \n",
       "26436       1.0                     NaN           70.0             1.0   \n",
       "26437       1.0                     NaN           96.0             1.0   \n",
       "26438       1.0                     NaN           69.0             1.0   \n",
       "26439       1.0                     NaN           87.0             1.0   \n",
       "\n",
       "                                                  Lyrics            Artist  \n",
       "0      [Chorus 1]\\n(Still)\\nThough you broke my heart...     Bill Anderson  \n",
       "1      I'm coming home I'm coming\\nI'm coming home I'...      Bobby Vinton  \n",
       "2      Text comes on screen reading A Netflix Origin...      Russian Doll  \n",
       "3      S-A-T-U-R-D-A-Y night!\\nS-A-T-U-R-D-A-Y night!...  Bay City Rollers  \n",
       "4      [Verse 1: Joey Tempest]\\nWhen lights go down\\n...            Europe  \n",
       "...                                                  ...               ...  \n",
       "26435  Saludos, my darlings\\nAnd you know who you are...     Billy Crystal  \n",
       "26436  [Intro]\\nOh yeah, oh yeah, oh yeah, oh yeah\\n\\...        Mary Wells  \n",
       "26437  Now that I know\\nWhat it is, boy\\nGood, good l...      Ruby Andrews  \n",
       "26438  I believed all love has gone\\nI've no strength...  Bay City Rollers  \n",
       "26439  You made me love you\\nI didn't wanna do it\\nI ...   Nat King Cole  \n",
       "\n",
       "[26440 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tx_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_artist(df,column):\n",
    "    \"\"\"\n",
    "    This function cleans the artist and performer names to make the comparison easy\n",
    "    df = dataframe\n",
    "    column = name of the column to clean\n",
    "    \"\"\"\n",
    "    df = df\n",
    "    df[column] = df[column].str.lower()\n",
    "    df[column] = df[column].str.replace(r\"é|è\",\"e\").str.replace(r\"â\",\"a\").str.replace(r\"ô\",\"o\")\n",
    "    df[column] = df[column].str.replace(r\"[^A-Za-z0-9]+\",\" \")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_artist(df,'Performer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_artist(df,'Artist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if the comparison works\n",
    "\n",
    "data_frame = pd.DataFrame(\n",
    "    {'col1':{\n",
    "        1:'the cat crossed a road',\n",
    "        2:'the dog barked',\n",
    "        3:'the chicken barked',},\n",
    "    'col2':{\n",
    "        1: 'the cat alligator',\n",
    "        2: 'some words here',\n",
    "        3: 'chicken soup'}}\n",
    ")\n",
    "\n",
    "# output the overlap as a list\n",
    "output = [[word for word in line1.split() if word in line2.split()] \n",
    "    for line1, line2 in zip(data_frame['col1'].values, data_frame['col2'].values)]\n",
    "\n",
    "# To add your new values a column\n",
    "data_frame['col3'] = output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'cat'], [], ['chicken']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the lyric downloaded is from the same artist or not\n",
    "output = [\n",
    "    [word for word in line1.split() if word in line2.split()] \n",
    "    for line1, line2 in zip(df['Performer'].values, df['Artist'].values)\n",
    "]\n",
    "\n",
    "# To add your new values a column\n",
    "df['common'] = output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the faulty rows in an excel file to \n",
    "\n",
    "df[df[\"common\"].str.len() == 0].to_excel('faulty2.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the right lyrics and discarding the rest\n",
    "df = df[df[\"common\"].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(df,column):\n",
    "    \"\"\"\n",
    "    This function cleans the words without importance and fix the format of the dataframe's column lyrics \n",
    "    parameters:\n",
    "    df = dataframe\n",
    "    column = name of the column to clean\n",
    "    \"\"\"\n",
    "    df = df\n",
    "    df[column] = df[column].str.lower()\n",
    "    df[column] = df[column].str.replace(r\"verse |[1|2|3]|chorus|bridge|outro\",\"\").str.replace(\"[\",\"\").str.replace(\"]\",\"\")\n",
    "    df[column] = df[column].str.lower().str.replace(r\"instrumental|intro|guitar|solo\",\"\")\n",
    "    df[column] = df[column].str.replace(r\"[^\\w\\d'\\s]+\",\"\")\n",
    "    df[column] = df[column].str.strip()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-941c595dc177>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.lower()\n",
      "<ipython-input-25-941c595dc177>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.replace(r\"verse |[1|2|3]|chorus|bridge|outro\",\"\").str.replace(\"[\",\"\").str.replace(\"]\",\"\")\n",
      "<ipython-input-25-941c595dc177>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.lower().str.replace(r\"instrumental|intro|guitar|solo\",\"\")\n",
      "<ipython-input-25-941c595dc177>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.replace(r\"[^\\w\\d'\\s]+\",\"\")\n",
      "<ipython-input-25-941c595dc177>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].str.strip()\n"
     ]
    }
   ],
   "source": [
    "#cleaning and transforming the data using the previously built function\n",
    "df = clean_lyrics(df,'Lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data into a csv file\n",
    "#df.to_csv('lyrics.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics_to_words(document):\n",
    "    \"\"\"\n",
    "    This function splits the text of lyrics to  single words, removing stopwords and doing the lemmatization to each word\n",
    "    parameters:\n",
    "    document: text to split to single words\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    exclude = set(string.punctuation)\n",
    "    lemma = WordNetLemmatizer()\n",
    "    stopwordremoval = \" \".join([i for i in document.lower().split() if i not in stop_words])\n",
    "    punctuationremoval = ''.join(ch for ch in stopwordremoval if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word,get_wordnet_pos(word)) for word in punctuationremoval.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1): \n",
    "     # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x) \n",
    "    \n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stores unique words of each lyrics song into a new column called words \n",
    "\n",
    "#list used to store the words\n",
    "words = []\n",
    "#iterate trought each lyric and split unique words appending the result into the words list\n",
    "df = df.reset_index(drop=True)\n",
    "for word in df['Lyrics'].tolist():\n",
    "    words.append(unique(lyrics_to_words(word).split()))\n",
    "\n",
    "#create the new column with the information of words lists \n",
    "df['words'] = words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stores all words of each lyrics song into a new column called words \n",
    "\n",
    "#list used to store the words\n",
    "all_words = []\n",
    "#iterate trought each lyric and split unique words appending the result into the words list\n",
    "df = df.reset_index(drop=True)\n",
    "for word in df['Lyrics'].tolist():\n",
    "    all_words.append(lyrics_to_words(word).split())\n",
    "\n",
    "#create the new column with the information of words lists \n",
    "df['all_words'] = all_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = []\n",
    "for i in range(len(words)):\n",
    "    wordCount.append(len(words[i]))\n",
    "    \n",
    "df['wordCount'] = wordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWordCount = []\n",
    "for i in range(len(all_words)):\n",
    "    allWordCount.append(len(all_words[i]))\n",
    "    \n",
    "df['allWordCount'] = allWordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tx_data['wordCount']=wordCount\n",
    "#tx_data.to_csv('lyrics_with_word_count.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data into a csv file\n",
    "#df.to_csv('words_proper_all.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big = df.index[df['wordCount'] > 400].tolist()\n",
    "len(big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#big = pd.DataFrame(big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_data = pd.read_pickle('clean_dataset_all_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detecting the languages of the song\n",
    "from langdetect import detect, detect_langs,DetectorFactory\n",
    "myText = df['Lyrics'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = []\n",
    "DetectorFactory.seed = 0\n",
    "for text in myText:\n",
    "    try:\n",
    "        languages.append(detect(text))\n",
    "    except:\n",
    "        languages.append(\"Error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['languages'] = languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "for i in range(0,len(languages)):\n",
    "    if languages[i]!='en':\n",
    "        a = a+1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging the negated words for negation handling later\n",
    "\n",
    "import re\n",
    "# The following code tags the lyrics with a NEG_ tag for negated words\n",
    "transformed = []\n",
    "clean_string = df['Lyrics'].str.replace(\"n't\",\"nt\").str.replace(\"\\n\",\".\\n\")\n",
    "for text in clean_string:\n",
    "    transformed.append(re.sub(r'\\b(?:never|no|nothing|nowhere|noone|none|not|havent|hasnt|hadnt|cant|couldnt|shouldnt|wont|wouldnt|dont|doesnt|didnt|isnt|arent|aint)\\b[\\w\\s]+[^\\w\\s]', \n",
    "        lambda match: re.sub(r'(\\s+)(\\w+)', r'\\1NEG_\\2', match.group(0)), \n",
    "        text,\n",
    "        flags=re.IGNORECASE))\n",
    "    \n",
    "#The following code removes the negative words from the lyrics\n",
    "without = []\n",
    "for strng in transformed:\n",
    "    without.append(re.sub('(?:\\s)NEG[^, ]*', '', strng))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of words without any negation that is ready for processing with emotion library\n",
    "\n",
    "#list used to store the words\n",
    "without_negations = []\n",
    "#iterate trought each lyric and split unique words appending the result into the words list\n",
    "for word in without:\n",
    "    without_negations.append(lyrics_to_words(word).split())\n",
    "\n",
    "#create the new column with the information of words lists \n",
    "df['without_negations'] = without_negations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes the NEG_ tags and gives a list of negated words ready for processing with emotion library\n",
    "# Function to find the words with the tag NEG_\n",
    "def negated_string(text):\n",
    "    text2 = re.findall(r'\\bNEG\\w+', text)\n",
    "    clean = []\n",
    "    for word in text2:\n",
    "        clean.append(re.sub('NEG_','',word))\n",
    "    clean_text = ' '.join(clean) \n",
    "    return clean_text\n",
    "\n",
    "only_negated = []\n",
    "for text in transformed:\n",
    "    only_negated.append(negated_string(text))\n",
    "\n",
    "#list used to store the words\n",
    "only_negations = []\n",
    "#iterate trought each lyric and split unique words appending the result into the words list\n",
    "for word in only_negated:\n",
    "    only_negations.append(lyrics_to_words(word).split())\n",
    "\n",
    "#create the new column with the information of words lists \n",
    "df['only_negations'] = only_negations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data into a csv file\n",
    "df_clean.to_csv('clean_dataset_all_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_pickle('clean_dataset_all_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
